{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation\n",
    "http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('abcnews-date-text.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text  index\n",
       "0  aba decides against community broadcasting lic...      0\n",
       "1     act fire witnesses must be aware of defamation      1\n",
       "2     a g calls for infrastructure protection summit      2\n",
       "3           air nz staff in aust strike for pay rise      3\n",
       "4      air nz strike to affect australian travellers      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = data[['headline_text']]\n",
    "documents['index'] = documents.index\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 1186018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text  index\n",
       "0  aba decides against community broadcasting lic...      0\n",
       "1     act fire witnesses must be aware of defamation      1\n",
       "2     a g calls for infrastructure protection summit      2\n",
       "3           air nz staff in aust strike for pay rise      3\n",
       "4      air nz strike to affect australian travellers      4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Total number of documents: {len(documents)}\")\n",
    "documents.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/john/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2020)\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(token):\n",
    "    lem_token = WordNetLemmatizer().lemmatize(token, pos='v')\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    return stemmer.stem(lem_token)\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document: \n",
      "['ratepayers', 'group', 'wants', 'compulsory', 'local', 'govt', 'voting']\n",
      "\n",
      "Tokenized and lemmatized document: \n",
      "['ratepay', 'group', 'want', 'compulsori', 'local', 'govt', 'vote']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "\n",
    "print(f\"Original document: \\n{doc_sample.split()}\\n\")\n",
    "print(f\"Tokenized and lemmatized document: \\n{preprocess(doc_sample)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [decid, communiti, broadcast, licenc]\n",
       "1                        [wit, awar, defam]\n",
       "2    [call, infrastructur, protect, summit]\n",
       "3               [staff, aust, strike, rise]\n",
       "4      [strike, affect, australian, travel]\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['headline_text'].map(preprocess)\n",
    "processed_docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words on the Data set\n",
    "\n",
    "Create a dictionary from 'processed_docs' containing the number of times a word appears in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 67118 words in total\n",
      "0 broadcast\n",
      "1 communiti\n",
      "2 decid\n",
      "3 licenc\n",
      "4 awar\n",
      "5 defam\n",
      "6 wit\n",
      "7 call\n",
      "8 infrastructur\n",
      "9 protect\n",
      "10 summit\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "print(f\"There are {len(dictionary)} words in total\")\n",
    "\n",
    "count = 0\n",
    "for k,v in dictionary.items():\n",
    "    print(k,v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out tokens that appear in\n",
    "* less than 15 documents (absolute number) or\n",
    "* more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "* after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 14939 words in filtered dictionary in total\n"
     ]
    }
   ],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "print(f\"There are {len(dictionary)} words in filtered dictionary in total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim doc2bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words and frequencies in the sentence:\n",
      "[(162, 1), (240, 1), (292, 1), (589, 1), (838, 1), (3567, 1), (3568, 1)]\n",
      "['govt', 'group', 'vote', 'local', 'want', 'compulsori', 'ratepay']\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "print(f\"Words and frequencies in the sentence:\\n{bow_corpus[4310]}\")\n",
    "sent = []\n",
    "for word_num, freq in bow_corpus[4310]:\n",
    "    sent.append(dictionary[word_num])\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(162, 0.25617525269671065),\n",
       " (240, 0.3011111395538523),\n",
       " (292, 0.33416888830557095),\n",
       " (589, 0.33377677352466983),\n",
       " (838, 0.3121925622107832),\n",
       " (3567, 0.5158075532653446),\n",
       " (3568, 0.5070590825348879)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "corpus_tfidf[4310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus,\n",
    "                                       num_topics=10,\n",
    "                                       id2word=dictionary,\n",
    "                                       passes=5,\n",
    "                                       workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 \n",
      "Words: 0.027*\"home\" + 0.023*\"live\" + 0.020*\"hous\" + 0.016*\"bank\" + 0.015*\"guilti\" + 0.015*\"perth\" + 0.014*\"return\" + 0.011*\"care\" + 0.011*\"violenc\" + 0.010*\"white\"\n",
      "Topic 1 \n",
      "Words: 0.032*\"elect\" + 0.025*\"kill\" + 0.018*\"coast\" + 0.014*\"tasmanian\" + 0.013*\"attack\" + 0.013*\"say\" + 0.012*\"victoria\" + 0.012*\"deal\" + 0.012*\"gold\" + 0.010*\"state\"\n",
      "Topic 2 \n",
      "Words: 0.035*\"court\" + 0.026*\"news\" + 0.023*\"face\" + 0.014*\"game\" + 0.014*\"student\" + 0.013*\"tell\" + 0.012*\"polit\" + 0.012*\"review\" + 0.012*\"announc\" + 0.011*\"famili\"\n",
      "Topic 3 \n",
      "Words: 0.024*\"melbourn\" + 0.020*\"die\" + 0.019*\"canberra\" + 0.017*\"health\" + 0.015*\"hospit\" + 0.015*\"royal\" + 0.015*\"rural\" + 0.014*\"crash\" + 0.013*\"interview\" + 0.013*\"chang\"\n",
      "Topic 4 \n",
      "Words: 0.048*\"polic\" + 0.028*\"charg\" + 0.023*\"murder\" + 0.019*\"woman\" + 0.019*\"donald\" + 0.016*\"shoot\" + 0.016*\"alleg\" + 0.014*\"miss\" + 0.012*\"trial\" + 0.012*\"arrest\"\n",
      "Topic 5 \n",
      "Words: 0.024*\"market\" + 0.023*\"south\" + 0.018*\"protest\" + 0.016*\"farmer\" + 0.015*\"australia\" + 0.015*\"fight\" + 0.015*\"busi\" + 0.015*\"rise\" + 0.014*\"price\" + 0.013*\"fall\"\n",
      "Topic 6 \n",
      "Words: 0.042*\"australian\" + 0.037*\"trump\" + 0.024*\"world\" + 0.023*\"queensland\" + 0.017*\"adelaid\" + 0.017*\"women\" + 0.016*\"open\" + 0.014*\"final\" + 0.013*\"record\" + 0.012*\"win\"\n",
      "Topic 7 \n",
      "Words: 0.031*\"australia\" + 0.025*\"nation\" + 0.022*\"north\" + 0.021*\"test\" + 0.018*\"island\" + 0.014*\"west\" + 0.013*\"drum\" + 0.013*\"stori\" + 0.012*\"scott\" + 0.012*\"morrison\"\n",
      "Topic 8 \n",
      "Words: 0.040*\"year\" + 0.025*\"china\" + 0.019*\"jail\" + 0.018*\"bushfir\" + 0.017*\"death\" + 0.016*\"peopl\" + 0.015*\"sentenc\" + 0.014*\"life\" + 0.013*\"farm\" + 0.012*\"road\"\n",
      "Topic 9 \n",
      "Words: 0.024*\"govern\" + 0.017*\"plan\" + 0.015*\"feder\" + 0.014*\"tasmania\" + 0.014*\"water\" + 0.012*\"council\" + 0.012*\"fund\" + 0.012*\"indigen\" + 0.010*\"call\" + 0.010*\"communiti\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic {} \\nWords: {}\".format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf,\n",
    "                                       num_topics=10,\n",
    "                                       id2word=dictionary,\n",
    "                                       passes=2,\n",
    "                                       workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 \n",
      "Words: 0.022*\"news\" + 0.009*\"queensland\" + 0.009*\"north\" + 0.009*\"climat\" + 0.008*\"australia\" + 0.008*\"south\" + 0.007*\"drought\" + 0.007*\"korea\" + 0.007*\"scott\" + 0.006*\"christma\"\n",
      "Topic 1 \n",
      "Words: 0.017*\"rural\" + 0.015*\"govern\" + 0.009*\"health\" + 0.007*\"monday\" + 0.007*\"nation\" + 0.007*\"thursday\" + 0.006*\"care\" + 0.005*\"financ\" + 0.005*\"violenc\" + 0.005*\"fund\"\n",
      "Topic 2 \n",
      "Words: 0.014*\"donald\" + 0.011*\"final\" + 0.009*\"australia\" + 0.009*\"leagu\" + 0.008*\"world\" + 0.007*\"sport\" + 0.007*\"cricket\" + 0.006*\"rugbi\" + 0.006*\"open\" + 0.006*\"video\"\n",
      "Topic 3 \n",
      "Words: 0.012*\"market\" + 0.009*\"wednesday\" + 0.008*\"share\" + 0.008*\"wall\" + 0.007*\"australian\" + 0.006*\"street\" + 0.006*\"brexit\" + 0.005*\"coal\" + 0.005*\"facebook\" + 0.005*\"toni\"\n",
      "Topic 4 \n",
      "Words: 0.012*\"royal\" + 0.011*\"stori\" + 0.009*\"commiss\" + 0.009*\"turnbul\" + 0.008*\"michael\" + 0.007*\"grandstand\" + 0.007*\"mother\" + 0.007*\"juli\" + 0.007*\"sentenc\" + 0.006*\"jail\"\n",
      "Topic 5 \n",
      "Words: 0.010*\"elect\" + 0.007*\"labor\" + 0.007*\"liber\" + 0.006*\"say\" + 0.006*\"council\" + 0.006*\"plan\" + 0.005*\"peter\" + 0.005*\"senat\" + 0.005*\"august\" + 0.005*\"green\"\n",
      "Topic 6 \n",
      "Words: 0.019*\"countri\" + 0.014*\"hour\" + 0.014*\"drum\" + 0.012*\"live\" + 0.010*\"weather\" + 0.009*\"tuesday\" + 0.008*\"friday\" + 0.007*\"cattl\" + 0.007*\"andrew\" + 0.006*\"octob\"\n",
      "Topic 7 \n",
      "Words: 0.012*\"interview\" + 0.011*\"polic\" + 0.009*\"death\" + 0.009*\"shoot\" + 0.007*\"attack\" + 0.006*\"john\" + 0.005*\"inquest\" + 0.005*\"septemb\" + 0.005*\"suspect\" + 0.005*\"hunt\"\n",
      "Topic 8 \n",
      "Words: 0.029*\"trump\" + 0.019*\"crash\" + 0.011*\"die\" + 0.010*\"woman\" + 0.008*\"fatal\" + 0.008*\"morrison\" + 0.008*\"david\" + 0.007*\"miss\" + 0.007*\"polic\" + 0.007*\"search\"\n",
      "Topic 9 \n",
      "Words: 0.012*\"charg\" + 0.010*\"guilti\" + 0.010*\"alleg\" + 0.010*\"murder\" + 0.009*\"polic\" + 0.009*\"assault\" + 0.007*\"sexual\" + 0.007*\"drug\" + 0.007*\"abus\" + 0.007*\"plead\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print(\"Topic {} \\nWords: {}\".format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation by classifying sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratepay', 'group', 'want', 'compulsori', 'local', 'govt', 'vote']\n",
      "\n",
      "Score: 0.6377481818199158 \n",
      "Topic: 0.024*\"govern\" + 0.017*\"plan\" + 0.015*\"feder\" + 0.014*\"tasmania\" + 0.014*\"water\" + 0.012*\"council\" + 0.012*\"fund\" + 0.012*\"indigen\" + 0.010*\"call\" + 0.010*\"communiti\"\n",
      "\n",
      "Score: 0.26220080256462097 \n",
      "Topic: 0.024*\"market\" + 0.023*\"south\" + 0.018*\"protest\" + 0.016*\"farmer\" + 0.015*\"australia\" + 0.015*\"fight\" + 0.015*\"busi\" + 0.015*\"rise\" + 0.014*\"price\" + 0.013*\"fall\"\n",
      "\n",
      "Score: 0.012509556487202644 \n",
      "Topic: 0.032*\"elect\" + 0.025*\"kill\" + 0.018*\"coast\" + 0.014*\"tasmanian\" + 0.013*\"attack\" + 0.013*\"say\" + 0.012*\"victoria\" + 0.012*\"deal\" + 0.012*\"gold\" + 0.010*\"state\"\n",
      "\n",
      "Score: 0.012506111524999142 \n",
      "Topic: 0.031*\"australia\" + 0.025*\"nation\" + 0.022*\"north\" + 0.021*\"test\" + 0.018*\"island\" + 0.014*\"west\" + 0.013*\"drum\" + 0.013*\"stori\" + 0.012*\"scott\" + 0.012*\"morrison\"\n",
      "\n",
      "Score: 0.012506071478128433 \n",
      "Topic: 0.048*\"polic\" + 0.028*\"charg\" + 0.023*\"murder\" + 0.019*\"woman\" + 0.019*\"donald\" + 0.016*\"shoot\" + 0.016*\"alleg\" + 0.014*\"miss\" + 0.012*\"trial\" + 0.012*\"arrest\"\n",
      "\n",
      "Score: 0.012506060302257538 \n",
      "Topic: 0.027*\"home\" + 0.023*\"live\" + 0.020*\"hous\" + 0.016*\"bank\" + 0.015*\"guilti\" + 0.015*\"perth\" + 0.014*\"return\" + 0.011*\"care\" + 0.011*\"violenc\" + 0.010*\"white\"\n",
      "\n",
      "Score: 0.01250605471432209 \n",
      "Topic: 0.035*\"court\" + 0.026*\"news\" + 0.023*\"face\" + 0.014*\"game\" + 0.014*\"student\" + 0.013*\"tell\" + 0.012*\"polit\" + 0.012*\"review\" + 0.012*\"announc\" + 0.011*\"famili\"\n",
      "\n",
      "Score: 0.012505730614066124 \n",
      "Topic: 0.024*\"melbourn\" + 0.020*\"die\" + 0.019*\"canberra\" + 0.017*\"health\" + 0.015*\"hospit\" + 0.015*\"royal\" + 0.015*\"rural\" + 0.014*\"crash\" + 0.013*\"interview\" + 0.013*\"chang\"\n",
      "\n",
      "Score: 0.012505730614066124 \n",
      "Topic: 0.042*\"australian\" + 0.037*\"trump\" + 0.024*\"world\" + 0.023*\"queensland\" + 0.017*\"adelaid\" + 0.017*\"women\" + 0.016*\"open\" + 0.014*\"final\" + 0.013*\"record\" + 0.012*\"win\"\n",
      "\n",
      "Score: 0.012505730614066124 \n",
      "Topic: 0.040*\"year\" + 0.025*\"china\" + 0.019*\"jail\" + 0.018*\"bushfir\" + 0.017*\"death\" + 0.016*\"peopl\" + 0.015*\"sentenc\" + 0.014*\"life\" + 0.013*\"farm\" + 0.012*\"road\"\n"
     ]
    }
   ],
   "source": [
    "sample_id = 4310\n",
    "print(processed_docs[sample_id])\n",
    "\n",
    "bow_corpus_sorted = sorted(lda_model[bow_corpus[sample_id]], key=lambda tup: -1*tup[1])\n",
    "for index, score in bow_corpus_sorted:\n",
    "    print(\"\\nScore: {} \\nTopic: {}\".format(score, lda_model.print_topic(index,10)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation by classifying sample document using LDA TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratepay', 'group', 'want', 'compulsori', 'local', 'govt', 'vote']\n",
      "\n",
      "Score: 0.6073325276374817 \n",
      "Topic: 0.010*\"elect\" + 0.007*\"labor\" + 0.007*\"liber\" + 0.006*\"say\" + 0.006*\"council\" + 0.006*\"plan\" + 0.005*\"peter\" + 0.005*\"senat\" + 0.005*\"august\" + 0.005*\"green\"\n",
      "\n",
      "Score: 0.292629212141037 \n",
      "Topic: 0.012*\"interview\" + 0.011*\"polic\" + 0.009*\"death\" + 0.009*\"shoot\" + 0.007*\"attack\" + 0.006*\"john\" + 0.005*\"inquest\" + 0.005*\"septemb\" + 0.005*\"suspect\" + 0.005*\"hunt\"\n",
      "\n",
      "Score: 0.012505852617323399 \n",
      "Topic: 0.017*\"rural\" + 0.015*\"govern\" + 0.009*\"health\" + 0.007*\"monday\" + 0.007*\"nation\" + 0.007*\"thursday\" + 0.006*\"care\" + 0.005*\"financ\" + 0.005*\"violenc\" + 0.005*\"fund\"\n",
      "\n",
      "Score: 0.01250543911010027 \n",
      "Topic: 0.012*\"market\" + 0.009*\"wednesday\" + 0.008*\"share\" + 0.008*\"wall\" + 0.007*\"australian\" + 0.006*\"street\" + 0.006*\"brexit\" + 0.005*\"coal\" + 0.005*\"facebook\" + 0.005*\"toni\"\n",
      "\n",
      "Score: 0.01250492874532938 \n",
      "Topic: 0.012*\"charg\" + 0.010*\"guilti\" + 0.010*\"alleg\" + 0.010*\"murder\" + 0.009*\"polic\" + 0.009*\"assault\" + 0.007*\"sexual\" + 0.007*\"drug\" + 0.007*\"abus\" + 0.007*\"plead\"\n",
      "\n",
      "Score: 0.01250461582094431 \n",
      "Topic: 0.019*\"countri\" + 0.014*\"hour\" + 0.014*\"drum\" + 0.012*\"live\" + 0.010*\"weather\" + 0.009*\"tuesday\" + 0.008*\"friday\" + 0.007*\"cattl\" + 0.007*\"andrew\" + 0.006*\"octob\"\n",
      "\n",
      "Score: 0.012504608370363712 \n",
      "Topic: 0.012*\"royal\" + 0.011*\"stori\" + 0.009*\"commiss\" + 0.009*\"turnbul\" + 0.008*\"michael\" + 0.007*\"grandstand\" + 0.007*\"mother\" + 0.007*\"juli\" + 0.007*\"sentenc\" + 0.006*\"jail\"\n",
      "\n",
      "Score: 0.012504399754106998 \n",
      "Topic: 0.022*\"news\" + 0.009*\"queensland\" + 0.009*\"north\" + 0.009*\"climat\" + 0.008*\"australia\" + 0.008*\"south\" + 0.007*\"drought\" + 0.007*\"korea\" + 0.007*\"scott\" + 0.006*\"christma\"\n",
      "\n",
      "Score: 0.012504365295171738 \n",
      "Topic: 0.014*\"donald\" + 0.011*\"final\" + 0.009*\"australia\" + 0.009*\"leagu\" + 0.008*\"world\" + 0.007*\"sport\" + 0.007*\"cricket\" + 0.006*\"rugbi\" + 0.006*\"open\" + 0.006*\"video\"\n",
      "\n",
      "Score: 0.012504077516496181 \n",
      "Topic: 0.029*\"trump\" + 0.019*\"crash\" + 0.011*\"die\" + 0.010*\"woman\" + 0.008*\"fatal\" + 0.008*\"morrison\" + 0.008*\"david\" + 0.007*\"miss\" + 0.007*\"polic\" + 0.007*\"search\"\n"
     ]
    }
   ],
   "source": [
    "sample_id = 4310\n",
    "print(processed_docs[sample_id])\n",
    "\n",
    "bow_corpus_sorted = sorted(lda_model_tfidf[bow_corpus[sample_id]], key=lambda tup: -1*tup[1])\n",
    "for index, score in bow_corpus_sorted:\n",
    "    print(\"\\nScore: {} \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index,10)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.39934155344963074 \n",
      "Topic: 0.035*\"court\" + 0.026*\"news\" + 0.023*\"face\" + 0.014*\"game\" + 0.014*\"student\"\n",
      "Score: 0.1457478106021881 \n",
      "Topic: 0.032*\"elect\" + 0.025*\"kill\" + 0.018*\"coast\" + 0.014*\"tasmanian\" + 0.013*\"attack\"\n",
      "Score: 0.1422124207019806 \n",
      "Topic: 0.024*\"govern\" + 0.017*\"plan\" + 0.015*\"feder\" + 0.014*\"tasmania\" + 0.014*\"water\"\n",
      "Score: 0.13493379950523376 \n",
      "Topic: 0.024*\"market\" + 0.023*\"south\" + 0.018*\"protest\" + 0.016*\"farmer\" + 0.015*\"australia\"\n",
      "Score: 0.1221773698925972 \n",
      "Topic: 0.040*\"year\" + 0.025*\"china\" + 0.019*\"jail\" + 0.018*\"bushfir\" + 0.017*\"death\"\n",
      "Score: 0.011119470000267029 \n",
      "Topic: 0.031*\"australia\" + 0.025*\"nation\" + 0.022*\"north\" + 0.021*\"test\" + 0.018*\"island\"\n",
      "Score: 0.011118164286017418 \n",
      "Topic: 0.024*\"melbourn\" + 0.020*\"die\" + 0.019*\"canberra\" + 0.017*\"health\" + 0.015*\"hospit\"\n",
      "Score: 0.011117043904960155 \n",
      "Topic: 0.042*\"australian\" + 0.037*\"trump\" + 0.024*\"world\" + 0.023*\"queensland\" + 0.017*\"adelaid\"\n",
      "Score: 0.011116147972643375 \n",
      "Topic: 0.027*\"home\" + 0.023*\"live\" + 0.020*\"hous\" + 0.016*\"bank\" + 0.015*\"guilti\"\n",
      "Score: 0.011116147972643375 \n",
      "Topic: 0.048*\"polic\" + 0.028*\"charg\" + 0.023*\"murder\" + 0.019*\"woman\" + 0.019*\"donald\"\n"
     ]
    }
   ],
   "source": [
    "unseen_doc = 'Today programming skills are required in many industries. Tech companies hire as never before.'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_doc))\n",
    "\n",
    "bow_vector_sorted = sorted(lda_model[bow_vector], key=lambda tup:-1*tup[1])\n",
    "for index, score in bow_vector_sorted:\n",
    "    print(\"Score: {} \\nTopic: {}\".format(score, lda_model.print_topic(index, 5)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.328738272190094 \n",
      "Topic: 0.017*\"rural\" + 0.015*\"govern\" + 0.009*\"health\" + 0.007*\"monday\" + 0.007*\"nation\"\n",
      "Score: 0.1798470914363861 \n",
      "Topic: 0.019*\"countri\" + 0.014*\"hour\" + 0.014*\"drum\" + 0.012*\"live\" + 0.010*\"weather\"\n",
      "Score: 0.17456398904323578 \n",
      "Topic: 0.010*\"elect\" + 0.007*\"labor\" + 0.007*\"liber\" + 0.006*\"say\" + 0.006*\"council\"\n",
      "Score: 0.13153955340385437 \n",
      "Topic: 0.029*\"trump\" + 0.019*\"crash\" + 0.011*\"die\" + 0.010*\"woman\" + 0.008*\"fatal\"\n",
      "Score: 0.12972453236579895 \n",
      "Topic: 0.012*\"charg\" + 0.010*\"guilti\" + 0.010*\"alleg\" + 0.010*\"murder\" + 0.009*\"polic\"\n",
      "Score: 0.011117811314761639 \n",
      "Topic: 0.012*\"market\" + 0.009*\"wednesday\" + 0.008*\"share\" + 0.008*\"wall\" + 0.007*\"australian\"\n",
      "Score: 0.011117374524474144 \n",
      "Topic: 0.022*\"news\" + 0.009*\"queensland\" + 0.009*\"north\" + 0.009*\"climat\" + 0.008*\"australia\"\n",
      "Score: 0.01111723855137825 \n",
      "Topic: 0.012*\"royal\" + 0.011*\"stori\" + 0.009*\"commiss\" + 0.009*\"turnbul\" + 0.008*\"michael\"\n",
      "Score: 0.011117043904960155 \n",
      "Topic: 0.012*\"interview\" + 0.011*\"polic\" + 0.009*\"death\" + 0.009*\"shoot\" + 0.007*\"attack\"\n",
      "Score: 0.011117042042315006 \n",
      "Topic: 0.014*\"donald\" + 0.011*\"final\" + 0.009*\"australia\" + 0.009*\"leagu\" + 0.008*\"world\"\n"
     ]
    }
   ],
   "source": [
    "unseen_doc = 'Today programming skills are required in many industries. Tech companies hire as never before.'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_doc))\n",
    "\n",
    "bow_vector_sorted = sorted(lda_model_tfidf[bow_vector], key=lambda tup:-1*tup[1])\n",
    "for index, score in bow_vector_sorted:\n",
    "    print(\"Score: {} \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
